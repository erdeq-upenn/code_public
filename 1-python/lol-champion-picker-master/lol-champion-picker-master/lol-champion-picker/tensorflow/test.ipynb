{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./new_data/dataset.txt','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "cleaned = lines[0][2:-2].split('], [') #[2:-2] to remove '[[' and  ']]', then separate each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(cleaned)\n",
    "test_set_size = int(np.floor(0.2 * data_size))\n",
    "train_set_size = int(data_size - test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./new_data/cleaned_train.txt\"\n",
    "TEST_DIR = \"./new_data/cleaned_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new text file with cleaned train data\n",
    "with open(TRAIN_DIR, 'w') as f:\n",
    "    for row in cleaned[:train_set_size]:\n",
    "        f.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new text file with cleaned data\n",
    "with open(TEST_DIR, 'w') as f:\n",
    "    for row in cleaned[train_set_size:]:\n",
    "        f.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    df_train = pd.read_csv(path, header=None, error_bad_lines=False)\n",
    "    df_train.rename(columns={52: \"result\"}, inplace=True) #rename the last col to results\n",
    "    df_train.dropna(inplace=True) #drop rows with NaN values\n",
    "    df_train[\"opposite_result\"] = df_train[\"result\"].map(lambda x: 1 if x == 0 else 0) \n",
    "    shuffled = df_train.sample(frac=1)\n",
    "    X_train = shuffled.iloc[:, :-2].as_matrix()\n",
    "    Y_train = shuffled[[\"result\", \"opposite_result\"]].as_matrix()\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    df_test = pd.read_csv(path, header=None, error_bad_lines=False)\n",
    "    df_test.rename(columns={52: \"result\"}, inplace=True) #rename the last col to results\n",
    "    df_test.dropna(inplace=True) #drop rows with NaN values\n",
    "    df_test[\"opposite_result\"] = df_test[\"result\"].map(lambda x: 1 if x == 0 else 0)\n",
    "    shuffled = df_test.sample(frac=1)\n",
    "    X_test = shuffled.iloc[:, :-2].as_matrix()\n",
    "    Y_test = shuffled[[\"result\", \"opposite_result\"]].as_matrix()\n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network model\n",
    "def create_model(num_features, lr=1E-3, two_fc=True, board_dir=\"\", dropout=0.5, activation=\"relu\"):\n",
    "    net = tflearn.input_data(shape=[None, num_features])\n",
    "    trunc_norm = tflearn.initializations.truncated_normal(stddev=1/np.sqrt(num_features))\n",
    "    net = tflearn.fully_connected(net, 100, weights_init=trunc_norm, activation=activation, name=\"fc1\")\n",
    "    #two_fc: whether to use 1 hidden layer or 2\n",
    "    if two_fc:\n",
    "        #dropout to prevent overfitting\n",
    "        net = tflearn.dropout(net, dropout)\n",
    "        net = tflearn.fully_connected(net, 80, activation=activation, weights_init=trunc_norm, name=\"fc2\")\n",
    "    net = tflearn.fully_connected(net, 2, activation=\"softmax\", weights_init=trunc_norm, name=\"fc3\")\n",
    "    net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy', learning_rate=lr)\n",
    "    #name of tensorboard file\n",
    "    tensorboard_dir = \"/tmp/tflearn_logs/lol/\" + board_dir\n",
    "    # Define model\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=2, tensorboard_dir=tensorboard_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, y_train, x_test, y_test, epoch=10):\n",
    "    # Start training (apply gradient descent algorithm)\n",
    "    model.fit(x_train, y_train, n_epoch=epoch, validation_set=(x_test, y_test),\n",
    "            snapshot_step=100, show_metric=True, run_id=\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8071: expected 53 fields, saw 61\\n'\n",
      "b'Skipping line 20160: expected 53 fields, saw 61\\n'\n",
      "b'Skipping line 6908: expected 53 fields, saw 61\\n'\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_train_data(TRAIN_DIR)\n",
    "X_test, Y_test = load_test_data(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weird bug, have to reset graph every time fit_model run again\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique file name for tensorboard visualization\n",
    "def make_hparam_string(learning_rate=1E-3, use_two_fc=True, epoch=5, dropout=0.5):\n",
    "    layers = \"2\" if use_two_fc else \"1\"\n",
    "    return \"lr=\" + str(learning_rate) + \",fc=\" + layers + \",epochs=\" + str(epoch) + \",dropout=\" + str(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal learning rate and number of layers\n",
    "def find_optimal_lr_and_fc():\n",
    "    for learn_rate in [1E-3, 1E-4, 1E-5]:\n",
    "        for use_two_fc in [True, False]:\n",
    "            param_string = make_hparam_string(learning_rate=learn_rate, use_two_fc=use_two_fc)\n",
    "            model = create_model(num_features=X_train.shape[1], lr=learn_rate, two_fc=use_two_fc, board_dir=param_string)\n",
    "            fit_model(model, X_train, Y_train, X_test, Y_test)\n",
    "            # weird bug, have to reset graph every time fit_model run again\n",
    "            tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find_optimal_lr_and_fc()\n",
    "# OPTIMAL LR: 1E-3\n",
    "# OPTIMAL LAYERS: Two hidden layers (0.6664 log loss vs 0.6669 log loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds optimal # of epochs\n",
    "def find_optimal_epochs():\n",
    "    for epoch in [5, 6, 7, 8, 9, 10]:\n",
    "        param_string = make_hparam_string(epoch=epoch)\n",
    "        model = create_model(num_features=X_train.shape[1], board_dir=param_string, dropout=dropout)\n",
    "        fit_model(model, X_train, Y_train, X_test, Y_test, epoch=epoch)\n",
    "        # weird bug, have to reset graph every time fit_model run again\n",
    "        tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find_optimal_epochs()\n",
    "# OPTIMAL EPOCHS: Around 10 (minimal differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4159  | total loss: \u001b[1m\u001b[32m0.13946\u001b[0m\u001b[0m | time: 19.665s\n",
      "| Adam | epoch: 010 | loss: 0.13946 - acc: 0.9457 -- iter: 26560/26566\n",
      "Training Step: 4160  | total loss: \u001b[1m\u001b[32m0.14285\u001b[0m\u001b[0m | time: 20.735s\n",
      "| Adam | epoch: 010 | loss: 0.14285 - acc: 0.9449 | val_loss: 0.15912 - val_acc: 0.9448 -- iter: 26566/26566\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = create_model(num_features=X_train.shape[1], board_dir=\"relu,epochs=10\")\n",
    "fit_model(model, X_train, Y_train, X_test, Y_test, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/borisyue/Desktop/lol-champion-picker/lol-champion-picker/tensorflow/model/tflearnlol.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('model/tflearnlol.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/borisyue/Desktop/lol-champion-picker/lol-champion-picker/tensorflow/model/tflearnlol.model\n"
     ]
    }
   ],
   "source": [
    "model.load('model/tflearnlol.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = np.zeros(276)\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets[59] = 1\n",
    "buckets[57] = 1\n",
    "buckets[62] = 1\n",
    "buckets[97] = 1\n",
    "buckets[117] = 1\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets[138 + 67] = 1\n",
    "buckets[138 + 87] = 1\n",
    "buckets[138 + 1] = 1\n",
    "buckets[138 + 46] = 1\n",
    "buckets[138 + 48] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = np.array(buckets).reshape(1, 276)\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98279852,  0.01720144]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
